<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Multimodal learning on graphs | Multimodal Representation Learning on Graphs</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="Multimodal learning on graphs" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Multimodal Graph Learning overview table." />
<meta property="og:description" content="Multimodal Graph Learning overview table." />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="Multimodal Representation Learning on Graphs" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Multimodal learning on graphs" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"Multimodal Graph Learning overview table.","headline":"Multimodal learning on graphs","name":"Multimodal Representation Learning on Graphs","url":"http://localhost:4000/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Multimodal Representation Learning on Graphs" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Multimodal Representation Learning on Graphs</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/">Multimodal learning on graphs</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <h1 id="multimodal-learning-on-graphs">Multimodal learning on graphs</h1>

<p>Artificial intelligence on graphs (graph AI) has achieved remarkable success in modeling complex systems, ranging from dynamical systems in biology to interacting particle systems in physics. The increasingly hetero- geneous graph datasets call for multimodal graph AI algorithms to combine multiple inductive biasesâ€”the set of assumptions that algorithms use to predict outputs of given inputs that they have not yet encountered. Learning on multimodal graph datasets presents fundamental challenges because inductive biases can vary by data modality and graphs might not be explicitly given in the input. To address these challenges, multimodal graph AI methods combine multiple modalities while leveraging cross-modal dependencies. Here, we survey 142 studies in graph AI and realize that diverse datasets are increasingly combined using graphs and fed into sophisticated multimodal models. These models stratify into image-, language-, and knowledge-grounded multimodal graph AI methods. Using this categorization of state-of-the-art methods, we put forward an algorithmic blueprint for multimodal graph AI, which we use to study existing methods and standardize the design of future methods for highly complex systems.</p>

<p><img src="/images/Figure1.jpg" alt="align=&quot;center&quot;" />
<em>Shown on the left are the different data modalities covered in our multimodal graph learning perspective. Shown on the right are key machine learning tasks for which multimodal graph learning has been used successfully. This Perspective introduces the multimodal graph learning (MGL) blueprint that serves as a unifying framework within which multimodal graph neural architectures can be expressed. It also surveys applications of MGL in computer vision, natural language processing, and natural sciences. This website displays these studies in a supplementary table and how they fall under the MGL blueprint.</em></p>

<p>For more information please read our perspective <a href="https://arxiv.org/abs/2209.03299">here</a>.</p>

<h1 id="table">Table</h1>

<p>This website hosts a table to highlight selected studies from the perspective on <a href="https://arxiv.org/abs/2209.03299">multimodal graph learning (MGL)</a> and the community in a supplementary table and how they fall under the MGL blueprint. <strong>This table is live meaning anyone can submit a study to be considered for this table</strong>and we will update the table <strong>every week</strong>. Entries are grouped by application area. This table is meant as (1) a resouorce to those looking to use MGL for their application but unsure how each compoonent is realized in practice and (2) a map of MGL as an emerging field.</p>

<table>
  
    
    <tr>
      
        <th>Method Name</th>
      
        <th> Identifying Entities</th>
      
        <th> Uncovering Topology</th>
      
        <th> Propagating Information</th>
      
        <th> Mixing Representations</th>
      
        <th> Application</th>
      
    </tr>
    

    <tr class="row1">
<td class="col1">
		
			
		    <a href="https://arxiv.org/abs/2008.02457"> FuNet </a>
		
    </td><td class="col2">
		
		     Hyperspectral Pixels
		
    </td><td class="col3">
		
		    Similarities between two vertices defined by radial basis function
		
    </td><td class="col4">
		
		     miniGCN (mini-batching with GCNs)
		
    </td><td class="col5">
		
		     Concatenation/Addition/Multiplication of GCN and CNN final layer features
		
    </td><td class="col6">
		
		     Hyperspectral image classification
		
    </td></tr>

  
</table>

<h2 id="use-this-link-to-submit-a-study-to-be-added-to-this-table">Use this <a href="https://forms.gle/ACBwCCfH6UzTeaBZ8">link</a> to submit a study to be added to this table.</h2>


      </div>

    </main>

  </body>

</html>
